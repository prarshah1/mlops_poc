name: CI pipeline
# our diagram in
# integrate with dvc with mlflow
# move this to new registry
# remove any references - complete new
# implement shap pdp and subpopulation with model training and store the artifacts in mlflow, lift- roc, auc, confusion matrix


# infer - load mlflow.pyfunc, or initialize pyspark and load

#model = mlflow.pyfunc.load_model(model_path)model.predict(model_input)
#
## load input data table as a Spark DataFrameinput_data = spark.table(input_table_name)model_udf = mlflow.pyfunc.spark_udf(model_path)df = input_data.withColumn("prediction", model_udf())


on:
  pull_request:
    branches:
      - main
    tags-ignore:
      - 'v*' # this tag type is used for release pipelines hk

jobs:
  ci-pipeline:

    runs-on: ubuntu-latest
    strategy:
      max-parallel: 4

    env:
      DATABRICKS_HOST: https://dbc-79ee8895-9a53.cloud.databricks.com
      DATABRICKS_TOKEN: dapib7b9ee9e57d9d622c5f14a9b343fdf3b
#      DATABRICKS_HOST: ${{ secrets.DATABRICKS_PROD_HOST }}
#      DATABRICKS_TOKEN: ${{ secrets.DATABRICKS_PROD_TOKEN }}

    clear-cache:
      runs-on: ubuntu-latest
      steps:
        - name: Clear cache
          uses: actions/github-script@v6
          with:
            script: |
              console.log("About to clear")
              const caches = await github.rest.actions.getActionsCacheList({
                owner: context.repo.owner,
                repo: context.repo.repo,
              })
              for (const cache of caches.data.actions_caches) {
                console.log(cache)
                github.rest.actions.deleteActionsCacheById({
                  owner: context.repo.owner,
                  repo: context.repo.repo,
                  cache_id: cache.id,
                })
              }
              console.log("Clear completed")
    steps:
      - uses: actions/checkout@v3

      - name: Set up Python
        uses: actions/setup-python@v3
        with:
          python-version: 3.9.6
          cache: "poetry"

      - name: Install pip
        run: |
          python -m pip install --upgrade pip

      - name: Install dependencies and project in dev mode
        run: |
          pip install -r unit-requirements.txt
          pip install -e .

      - name: Run dvc
        run: |
          dvc pull
          dvc repro
          dvc push

      - name: Run unit tests
        run: |
          echo "Launching unit tests"
          pytest tests/unit

      - name: Deploy integration test [staging environment]
        run: |
          dbx deploy --jobs=STAGING-telco-churn-sample-integration-test --environment=staging --files-only

      - name: Run integration test [staging environment]
        run: |
          dbx launch --job=STAGING-telco-churn-sample-integration-test --environment=staging --as-run-submit --trace
